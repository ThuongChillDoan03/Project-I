{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d363ee0d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-08T18:51:50.766290Z",
     "iopub.status.busy": "2024-05-08T18:51:50.765930Z",
     "iopub.status.idle": "2024-05-08T18:51:54.717608Z",
     "shell.execute_reply": "2024-05-08T18:51:54.716789Z"
    },
    "papermill": {
     "duration": 3.963989,
     "end_time": "2024-05-08T18:51:54.720083",
     "exception": false,
     "start_time": "2024-05-08T18:51:50.756094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as scio\n",
    "import time\n",
    "import matplotlib\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4753d92a",
   "metadata": {
    "papermill": {
     "duration": 0.007642,
     "end_time": "2024-05-08T18:51:54.735658",
     "exception": false,
     "start_time": "2024-05-08T18:51:54.728016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**MOTSP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf8440f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T18:51:54.754319Z",
     "iopub.status.busy": "2024-05-08T18:51:54.753292Z",
     "iopub.status.idle": "2024-05-08T18:51:54.775589Z",
     "shell.execute_reply": "2024-05-08T18:51:54.774687Z"
    },
    "papermill": {
     "duration": 0.03432,
     "end_time": "2024-05-08T18:51:54.777753",
     "exception": false,
     "start_time": "2024-05-08T18:51:54.743433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TSPDataset(Dataset):\n",
    "\n",
    "    def __init__(self, size=50, num_samples=1e6, seed=None):\n",
    "        super(TSPDataset, self).__init__()\n",
    "\n",
    "        if seed is None:\n",
    "            seed = np.random.randint(123456789)\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        self.dataset = torch.rand((num_samples, 4, size))\n",
    "        self.dynamic = torch.zeros(num_samples, 1, size)\n",
    "        self.num_nodes = size\n",
    "        self.size = num_samples\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # (static, dynamic, start_loc)\n",
    "        return (self.dataset[idx], self.dynamic[idx], [])\n",
    "\n",
    "\n",
    "def update_mask(mask, dynamic, chosen_idx):\n",
    "    \"\"\"Marks the visited city, so it can't be selected a second time.\"\"\"\n",
    "    mask.scatter_(1, chosen_idx.unsqueeze(1), 0)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def reward(static, tour_indices, w1=1, w2=0):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    static: torch.FloatTensor containing static (e.g. x, y) data\n",
    "    tour_indices: torch.IntTensor of size (batch_size, num_cities)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Euclidean distance between consecutive nodes on the route. of size\n",
    "    (batch_size, num_cities)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the indices back into a tour\n",
    "    idx = tour_indices.unsqueeze(1).expand_as(static)\n",
    "    tour = torch.gather(static.data, 2, idx).permute(0, 2, 1)\n",
    "\n",
    "    # Make a full tour by returning to the start\n",
    "    y = torch.cat((tour, tour[:, :1]), dim=1)\n",
    "    # first 2 is xy coordinate, third column is another obj\n",
    "    y_dis = y[:, :, :2]\n",
    "    y_dis2 = y[:, :, 2:]\n",
    "\n",
    "    # Euclidean distance between each consecutive point\n",
    "    tour_len = torch.sqrt(torch.sum(torch.pow(y_dis[:, :-1] - y_dis[:, 1:], 2), dim=2))\n",
    "    obj1 = tour_len.sum(1).detach()\n",
    "\n",
    "    tour_len2 = torch.sqrt(torch.sum(torch.pow(y_dis2[:, :-1] - y_dis2[:, 1:], 2), dim=2))\n",
    "    obj2 = tour_len2.sum(1).detach()\n",
    "\n",
    "    obj = w1*obj1 + w2*obj2\n",
    "    return obj, obj1, obj2\n",
    "\n",
    "\n",
    "\n",
    "def render(static, tour_indices, save_path):\n",
    "    \"\"\"Plots the found tours.\"\"\"\n",
    "\n",
    "    plt.close('all')\n",
    "\n",
    "    num_plots = 3 if int(np.sqrt(len(tour_indices))) >= 3 else 1\n",
    "\n",
    "    _, axes = plt.subplots(nrows=num_plots, ncols=num_plots,\n",
    "                           sharex='col', sharey='row')\n",
    "\n",
    "    if num_plots == 1:\n",
    "        axes = [[axes]]\n",
    "    axes = [a for ax in axes for a in ax]\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "\n",
    "        # Convert the indices back into a tour\n",
    "        idx = tour_indices[i]\n",
    "        if len(idx.size()) == 1:\n",
    "            idx = idx.unsqueeze(0)\n",
    "\n",
    "        # End tour at the starting index\n",
    "        idx = idx.expand(static.size(1), -1)\n",
    "        idx = torch.cat((idx, idx[:, 0:1]), dim=1)\n",
    "\n",
    "        data = torch.gather(static[i].data, 1, idx).cpu().numpy()\n",
    "\n",
    "        #plt.subplot(num_plots, num_plots, i + 1)\n",
    "        ax.plot(data[0], data[1], zorder=1)\n",
    "        ax.scatter(data[0], data[1], s=4, c='r', zorder=2)\n",
    "        ax.scatter(data[0, 0], data[1, 0], s=20, c='k', marker='*', zorder=3)\n",
    "\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbca74ad",
   "metadata": {
    "papermill": {
     "duration": 0.007972,
     "end_time": "2024-05-08T18:51:54.793677",
     "exception": false,
     "start_time": "2024-05-08T18:51:54.785705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**ENCODER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dda027d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T18:51:54.811019Z",
     "iopub.status.busy": "2024-05-08T18:51:54.810694Z",
     "iopub.status.idle": "2024-05-08T18:51:54.816388Z",
     "shell.execute_reply": "2024-05-08T18:51:54.815581Z"
    },
    "papermill": {
     "duration": 0.016852,
     "end_time": "2024-05-08T18:51:54.818525",
     "exception": false,
     "start_time": "2024-05-08T18:51:54.801673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encodes the static & dynamic states using 1d Convolution.\"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv = nn.Conv1d(input_size, hidden_size, kernel_size=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.conv(input)\n",
    "        return output  # (batch, hidden_size, seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b086858c",
   "metadata": {
    "papermill": {
     "duration": 0.007814,
     "end_time": "2024-05-08T18:51:54.834437",
     "exception": false,
     "start_time": "2024-05-08T18:51:54.826623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b86d343f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T18:51:54.851404Z",
     "iopub.status.busy": "2024-05-08T18:51:54.851057Z",
     "iopub.status.idle": "2024-05-08T18:51:54.859496Z",
     "shell.execute_reply": "2024-05-08T18:51:54.858594Z"
    },
    "papermill": {
     "duration": 0.018914,
     "end_time": "2024-05-08T18:51:54.861322",
     "exception": false,
     "start_time": "2024-05-08T18:51:54.842408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"Calculates attention over the input nodes given the current state.\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        # W processes features from static decoder elements\n",
    "        self.v = nn.Parameter(torch.zeros((1, 1, hidden_size),\n",
    "                                          device=device, requires_grad=True))\n",
    "\n",
    "        self.W = nn.Parameter(torch.zeros((1, hidden_size, 3 * hidden_size),\n",
    "                                          device=device, requires_grad=True))\n",
    "\n",
    "    def forward(self, static_hidden, dynamic_hidden, decoder_hidden):\n",
    "\n",
    "        batch_size, hidden_size, _ = static_hidden.size()\n",
    "\n",
    "        hidden = decoder_hidden.unsqueeze(2).expand_as(static_hidden)\n",
    "        hidden = torch.cat((static_hidden, dynamic_hidden, hidden), 1)\n",
    "\n",
    "        # Broadcast some dimensions so we can do batch-matrix-multiply\n",
    "        v = self.v.expand(batch_size, 1, hidden_size)\n",
    "        W = self.W.expand(batch_size, hidden_size, -1)\n",
    "\n",
    "        attns = torch.bmm(v, torch.tanh(torch.bmm(W, hidden)))\n",
    "        attns = F.softmax(attns, dim=2)  # (batch, seq_len)\n",
    "        return attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ae8e50",
   "metadata": {
    "papermill": {
     "duration": 0.007922,
     "end_time": "2024-05-08T18:51:54.876812",
     "exception": false,
     "start_time": "2024-05-08T18:51:54.868890",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Pointer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a64efdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T18:51:54.894847Z",
     "iopub.status.busy": "2024-05-08T18:51:54.894519Z",
     "iopub.status.idle": "2024-05-08T18:51:54.907475Z",
     "shell.execute_reply": "2024-05-08T18:51:54.906545Z"
    },
    "papermill": {
     "duration": 0.024394,
     "end_time": "2024-05-08T18:51:54.909368",
     "exception": false,
     "start_time": "2024-05-08T18:51:54.884974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Pointer(nn.Module):\n",
    "    \"\"\"Calculates the next state given the previous state and input embeddings.\"\"\"\n",
    "\n",
    "    def __init__(self, hidden_size, num_layers=1, dropout=0.2):\n",
    "        super(Pointer, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Used to calculate probability of selecting next state\n",
    "        self.v = nn.Parameter(torch.zeros((1, 1, hidden_size),\n",
    "                                          device=device, requires_grad=True))\n",
    "\n",
    "        self.W = nn.Parameter(torch.zeros((1, hidden_size, 2 * hidden_size),\n",
    "                                          device=device, requires_grad=True))\n",
    "\n",
    "        # Used to compute a representation of the current decoder output\n",
    "        # GRU（输入dim，隐含层dim，层数）\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=dropout if num_layers > 1 else 0)\n",
    "        self.encoder_attn = Attention(hidden_size)\n",
    "\n",
    "        self.drop_rnn = nn.Dropout(p=dropout)\n",
    "        self.drop_hh = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, static_hidden, dynamic_hidden, decoder_hidden, last_hh):\n",
    "\n",
    "        rnn_out, last_hh = self.gru(decoder_hidden.transpose(2, 1), last_hh)\n",
    "        rnn_out = rnn_out.squeeze(1)\n",
    "\n",
    "        # Always apply dropout on the RNN output\n",
    "        rnn_out = self.drop_rnn(rnn_out)\n",
    "        if self.num_layers == 1:\n",
    "            # If > 1 layer dropout is already applied\n",
    "            last_hh = self.drop_hh(last_hh) \n",
    "\n",
    "        # Given a summary of the output, find an  input context\n",
    "        enc_attn = self.encoder_attn(static_hidden, dynamic_hidden, rnn_out)\n",
    "        context = enc_attn.bmm(static_hidden.permute(0, 2, 1))  # (B, 1, num_feats)\n",
    "\n",
    "        # Calculate the next output using Batch-matrix-multiply ops\n",
    "        context = context.transpose(1, 2).expand_as(static_hidden)\n",
    "        energy = torch.cat((static_hidden, context), dim=1)  # (B, num_feats, seq_len)\n",
    "\n",
    "        v = self.v.expand(static_hidden.size(0), -1, -1)\n",
    "        W = self.W.expand(static_hidden.size(0), -1, -1)\n",
    "\n",
    "        probs = torch.bmm(v, torch.tanh(torch.bmm(W, energy))).squeeze(1)\n",
    "\n",
    "        return probs, last_hh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015342e9",
   "metadata": {
    "papermill": {
     "duration": 0.007917,
     "end_time": "2024-05-08T18:51:54.925283",
     "exception": false,
     "start_time": "2024-05-08T18:51:54.917366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**DRL_4TSP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1df041a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T18:51:54.942976Z",
     "iopub.status.busy": "2024-05-08T18:51:54.942679Z",
     "iopub.status.idle": "2024-05-08T18:51:54.955953Z",
     "shell.execute_reply": "2024-05-08T18:51:54.954716Z"
    },
    "papermill": {
     "duration": 0.024354,
     "end_time": "2024-05-08T18:51:54.957699",
     "exception": true,
     "start_time": "2024-05-08T18:51:54.933345",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 117)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:117\u001b[0;36m\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class DRL4TSP(nn.Module): \n",
    "    \"\"\"Defines the main Encoder, Decoder, and Pointer combinatorial models.\n",
    "​\n",
    "    Parameters\n",
    "    ----------\n",
    "    static_size: int\n",
    "        Defines how many features are in the static elements of the model\n",
    "        (e.g. 2 for (x, y) coordinates)\n",
    "    dynamic_size: int > 1\n",
    "        Defines how many features are in the dynamic elements of the model\n",
    "        (e.g. 2 for the VRP which has (load, demand) attributes. The TSP doesn't\n",
    "        have dynamic elements, but to ensure compatility with other optimization\n",
    "        problems, assume we just pass in a vector of zeros.\n",
    "    hidden_size: int\n",
    "        Defines the number of units in the hidden layer for all static, dynamic,\n",
    "        and decoder output units.\n",
    "    update_fn: function or None\n",
    "        If provided, this method is used to calculate how the input dynamic\n",
    "        elements are updated, and is called after each 'point' to the input element.\n",
    "    mask_fn: function or None\n",
    "        Allows us to specify which elements of the input sequence are allowed to\n",
    "        be selected. This is useful for speeding up training of the networks,\n",
    "        by providing a sort of 'rules' guidlines to the algorithm. If no mask\n",
    "        is provided, we terminate the search after a fixed number of iterations\n",
    "        to avoid tours that stretch forever\n",
    "    num_layers: int\n",
    "        Specifies the number of hidden layers to use in the decoder RNN\n",
    "    dropout: float\n",
    "        Defines the dropout rate for the decoder\n",
    "    \"\"\"\n",
    "​\n",
    "    def __init__(self, static_size, dynamic_size, hidden_size,\n",
    "                 update_fn=None, mask_fn=None, num_layers=1, dropout=0.):\n",
    "        super(DRL4TSP, self).__init__()\n",
    "​\n",
    "        if dynamic_size < 1:\n",
    "            raise ValueError(':param dynamic_size: must be > 0, even if the '\n",
    "                             'problem has no dynamic elements')\n",
    "​\n",
    "        self.update_fn = update_fn\n",
    "        self.mask_fn = mask_fn\n",
    "​\n",
    "        # Define the encoder & decoder models\n",
    "        self.static_encoder = Encoder(static_size, hidden_size)\n",
    "        self.dynamic_encoder = Encoder(dynamic_size, hidden_size)\n",
    "        self.decoder = Encoder(static_size, hidden_size)\n",
    "        self.pointer = Pointer(hidden_size, num_layers, dropout)\n",
    "​\n",
    "        for p in self.parameters():\n",
    "            if len(p.shape) > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "​\n",
    "        # Used as a proxy initial state in the decoder when not specified\n",
    "        self.x0 = torch.zeros((1, static_size, 1), requires_grad=True, device=device)\n",
    "​\n",
    "    def forward(self, static, dynamic, decoder_input=None, last_hh=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        static: Array of size (batch_size, feats, num_cities)\n",
    "            Defines the elements to consider as static. For the TSP, this could be\n",
    "            things like the (x, y) coordinates, which won't change\n",
    "        dynamic: Array of size (batch_size, feats, num_cities)\n",
    "            Defines the elements to consider as static. For the VRP, this can be\n",
    "            things like the (load, demand) of each city. If there are no dynamic\n",
    "            elements, this can be set to None\n",
    "        decoder_input: Array of size (batch_size, num_feats)\n",
    "            Defines the outputs for the decoder. Currently, we just use the\n",
    "            static elements (e.g. (x, y) coordinates), but this can technically\n",
    "            be other things as well\n",
    "        last_hh: Array of size (batch_size, num_hidden)\n",
    "            Defines the last hidden state for the RNN\n",
    "        \"\"\"\n",
    "​\n",
    "        batch_size, input_size, sequence_size = static.size()\n",
    "​\n",
    "        if decoder_input is None:\n",
    "            decoder_input = self.x0.expand(batch_size, -1, -1)\n",
    "​\n",
    "        # Always use a mask - if no function is provided, we don't update it\n",
    "        mask = torch.ones(batch_size, sequence_size, device=device)\n",
    "​\n",
    "        # Structures for holding the output sequences\n",
    "        tour_idx, tour_logp = [], []\n",
    "        max_steps = sequence_size if self.mask_fn is None else 1000\n",
    "​\n",
    "        # Static elements only need to be processed once, and can be used across\n",
    "        # all 'pointing' iterations. When / if the dynamic elements change,\n",
    "        # their representations will need to get calculated again.\n",
    "        static_hidden = self.static_encoder(static)\n",
    "        dynamic_hidden = self.dynamic_encoder(dynamic)\n",
    "​\n",
    "        for _ in range(max_steps):\n",
    "​\n",
    "            if not mask.byte().any():\n",
    "                break\n",
    "​\n",
    "            # ... but compute a hidden rep for each element added to sequence\n",
    "            decoder_hidden = self.decoder(decoder_input)\n",
    "​\n",
    "            probs, last_hh = self.pointer(static_hidden,\n",
    "                                          dynamic_hidden,\n",
    "                                          decoder_hidden, last_hh)\n",
    "            probs = F.softmax(probs + mask.log(), dim=1)\n",
    "​\n",
    "            # When training, sample the next step according to its probability.\n",
    "            # During testing, we can take the greedy approach and choose highest\n",
    "            if self.training:\n",
    "                m = torch.distributions.Categorical(probs)\n",
    "​\n",
    "                # Sometimes an issue with Categorical & sampling on GPU; See:\n",
    "                # https://github.com/pemami4911/neural-combinatorial-rl-pytorch/issues/5\n",
    "                ptr = m.sample()\n",
    "                while not torch.gather(mask, 1, ptr.data.unsqueeze(1)).byte().all():\n",
    "                    ptr = m.sample()\n",
    "                logp = m.log_prob(ptr)\n",
    "            else:\n",
    "                prob, ptr = torch.max(probs, 1)  # Greedy\n",
    "                logp = prob.log()\n",
    "​\n",
    "            # After visiting a node update the dynamic representation\n",
    "            if self.update_fn is not None:\n",
    "                dynamic = self.update_fn(dynamic, ptr.data)\n",
    "                dynamic_hidden = self.dynamic_encoder(dynamic)\n",
    "​\n",
    "                # Since we compute the VRP in minibatches, some tours may have\n",
    "                # number of stops. We force the vehicles to remain at the depot \n",
    "                # in these cases, and logp := 0\n",
    "                is_done = dynamic[:, 1].sum(1).eq(0).float()\n",
    "                logp = logp * (1. - is_done)\n",
    "​\n",
    "            # And update the mask so we don't re-visit if we don't need to\n",
    "            if self.mask_fn is not None:\n",
    "                mask = self.mask_fn(mask, dynamic, ptr.data).detach()\n",
    "​\n",
    "            tour_logp.append(logp.unsqueeze(1))\n",
    "            tour_idx.append(ptr.data.unsqueeze(1))\n",
    "​\n",
    "            decoder_input = torch.gather(static, 2,\n",
    "                                         ptr.view(-1, 1, 1)\n",
    "                                         .expand(-1, input_size, 1)).detach()\n",
    "​\n",
    "        tour_idx = torch.cat(tour_idx, dim=1)  # (batch_size, seq_len)\n",
    "        tour_logp = torch.cat(tour_logp, dim=1)  # (batch_size, seq_len)\n",
    "​\n",
    "        return tour_idx, tour_logp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d9a02f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**StateCritic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623ee394",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StateCritic(nn.Module): \n",
    "    \"\"\"Estimates the problem complexity.\n",
    "\n",
    "    This is a basic module that just looks at the log-probabilities predicted by\n",
    "    the encoder + decoder, and returns an estimate of complexity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, static_size, dynamic_size, hidden_size):\n",
    "        super(StateCritic, self).__init__()\n",
    "\n",
    "        self.static_encoder = Encoder(static_size, hidden_size)\n",
    "        self.dynamic_encoder = Encoder(dynamic_size, hidden_size)\n",
    "\n",
    "        # Define the encoder & decoder models\n",
    "        self.fc1 = nn.Conv1d(hidden_size * 2, 20, kernel_size=1)\n",
    "        self.fc2 = nn.Conv1d(20, 20, kernel_size=1)\n",
    "        self.fc3 = nn.Conv1d(20, 1, kernel_size=1)\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if len(p.shape) > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, static, dynamic):\n",
    "\n",
    "        # Use the probabilities of visiting each\n",
    "        static_hidden = self.static_encoder(static)\n",
    "        dynamic_hidden = self.dynamic_encoder(dynamic)\n",
    "\n",
    "        hidden = torch.cat((static_hidden, dynamic_hidden), 1)\n",
    "\n",
    "        output = F.relu(self.fc1(hidden))\n",
    "        output = F.relu(self.fc2(output))\n",
    "        output = self.fc3(output).sum(dim=2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95321e47",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**Dis_matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d631af6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dis_matrix(static, s_size):\n",
    "    static = static.squeeze(0) \n",
    "\n",
    "    # [2,20]\n",
    "    obj1 = static[:2, :]\n",
    "    # [20]\n",
    "    obj2 = static[2:, :]\n",
    "\n",
    "    l = obj1.size()[1]\n",
    "    obj1_matrix = np.zeros((l, l))\n",
    "    obj2_matrix = np.zeros((l, l))\n",
    "    for i in range(l):\n",
    "        for j in range(l):\n",
    "            if i != j:\n",
    "                obj1_matrix[i,j] = torch.sqrt(torch.sum(torch.pow(obj1[:, i] - obj1[:, j], 2))).detach()\n",
    "                if s_size == 3:\n",
    "                    obj2_matrix[i, j] = torch.abs(obj2[i] - obj2[j]).detach()\n",
    "                else:\n",
    "                    obj2_matrix[i, j] = torch.sqrt(torch.sum(torch.pow(obj2[:, i] - obj2[:, j], 2))).detach()\n",
    "\n",
    "    return obj1_matrix, obj2_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43763e4a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_mask(mask, dynamic, chosen_idx):\n",
    "    \"\"\"Marks the visited city, so it can't be selected a second time.\"\"\"\n",
    "    mask.scatter_(1, chosen_idx.unsqueeze(1), 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b5ecb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Kro_dataset(Dataset):\n",
    "\n",
    "    def __init__(self, num_nodes):\n",
    "        super(Kro_dataset, self).__init__()\n",
    "\n",
    "        x1 = np.loadtxt('/kaggle/input/mo-tsp1/krodata/kroA%d.tsp'%num_nodes, skiprows=6, usecols=(1, 2), delimiter=' ', dtype=float)\n",
    "        x1 = x1 / (np.max(x1,0))\n",
    "        x2 = np.loadtxt('/kaggle/input/mo-tsp1/krodata/kroB%d.tsp'%num_nodes, skiprows=6, usecols=(1, 2), delimiter=' ', dtype=float)\n",
    "        x2 = x2 / (np.max(x2,0))\n",
    "        x = np.concatenate((x1, x2),axis=1)\n",
    "        x = x.T\n",
    "        x = x.reshape(1, 4, num_nodes)\n",
    "\n",
    "        self.dataset = torch.from_numpy(x).float()\n",
    "        self.dynamic = torch.zeros(1, 1, num_nodes)\n",
    "        self.num_nodes = num_nodes\n",
    "        self.size = 1\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # (static, dynamic, start_loc)\n",
    "        return (self.dataset[idx], self.dynamic[idx], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d29e764",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the trained model and convert the obtained Pareto Front to the .mat file.\n",
    "# It is convenient to visualize it in matlab    \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "save_dir = \"/kaggle/input/mo-tsp3/tsp_transfer_100run_500000_5epoch_40city/40\"\n",
    "\n",
    "\n",
    "update_fn = None\n",
    "STATIC_SIZE = 4  # (x, y)\n",
    "DYNAMIC_SIZE = 1  # dummy for compatibility\n",
    "\n",
    "# claim model\n",
    "actor = DRL4TSP(STATIC_SIZE,\n",
    "                DYNAMIC_SIZE,\n",
    "                128,\n",
    "                update_fn,\n",
    "                update_mask,\n",
    "                1,\n",
    "                0.1).to(device)\n",
    "critic = StateCritic(STATIC_SIZE, DYNAMIC_SIZE, 128).to(device)\n",
    "\n",
    "# data 143\n",
    "# from Post_process.convet_kro_dataloader import Kro_dataset\n",
    "kro = 1\n",
    "D = 200\n",
    "if kro:\n",
    "    D = 200\n",
    "    Test_data = Kro_dataset(D)\n",
    "    Test_loader = DataLoader(Test_data, 1, False, num_workers=0)\n",
    "else:\n",
    "    # 40city_train: city20 13 city40 143 city70 2523\n",
    "    #\n",
    "    Test_data = TSPDataset(D, 1, 2523)\n",
    "    Test_loader = DataLoader(Test_data, 1, False, num_workers=0)\n",
    "\n",
    "iter_data = iter(Test_loader)\n",
    "static, dynamic, x0 = next(iter_data)\n",
    "static = static.to(device)\n",
    "dynamic = dynamic.to(device)\n",
    "x0 = x0.to(device) if len(x0) > 0 else None\n",
    "\n",
    "# load 50 models\n",
    "N=100\n",
    "w = np.arange(N+1)/N\n",
    "objs = np.zeros((N+1,2))\n",
    "start  = time.time()\n",
    "t1_all = 0\n",
    "t2_all = 0\n",
    "tours=[]\n",
    "for i in range(0, N+1):\n",
    "    t1 = time.time()\n",
    "    ac = os.path.join(save_dir, \"w_%2.2f_%2.2f\" % (1-w[i], w[i]),\"actor.pt\")\n",
    "    cri = os.path.join(save_dir, \"w_%2.2f_%2.2f\" % (1-w[i], w[i]),\"critic.pt\")\n",
    "    actor.load_state_dict(torch.load(ac, device))\n",
    "    critic.load_state_dict(torch.load(cri, device))\n",
    "    t1_all = t1_all + time.time()-t1\n",
    "    # calculate\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # t2 = time.time()\n",
    "        tour_indices, _ = actor.forward(static, dynamic, x0)\n",
    "        # t2_all = t2_all + time.time() - t2\n",
    "    _, obj1, obj2 = reward(static, tour_indices, 1-w[i], w[i])\n",
    "#     tours.append(tour_indices.cpu().numpy())\n",
    "#     objs[i,:] = [obj1, obj2]\n",
    "    tour_indices = tour_indices.cpu()\n",
    "    tours.append(tour_indices.numpy())\n",
    "    obj1 = obj1.cpu().item()\n",
    "    obj2 = obj2.cpu().item()\n",
    "    objs[i,:] = [obj1, obj2]\n",
    "\n",
    "print(\"time_load_model:%2.4f\"%t1_all)\n",
    "print(\"time_predict_model:%2.4f\"%t2_all)\n",
    "print(time.time()-start)\n",
    "\n",
    "print(tours)\n",
    "plt.figure()\n",
    "plt.plot(objs[:,0],objs[:,1],\"ro\")\n",
    "plt.show()\n",
    "\n",
    "# Convert to .mat\n",
    "obj1_matrix, obj2_matrix = dis_matrix(static, STATIC_SIZE)\n",
    "print(obj1_matrix)\n",
    "print(obj2_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a994902",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "**NSGA-II**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30dc3e5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af2ccb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "distance_matrix = obj1_matrix\n",
    "cost_matrix = obj2_matrix\n",
    "\n",
    "\n",
    "def Evaluate(tour, matrix):\n",
    "    value = 0\n",
    "    i = 0\n",
    "    while i < (len(tour)-1):\n",
    "        value += matrix[tour[i]][tour[i+1]]\n",
    "        i += 1\n",
    "        pass\n",
    "    value += matrix[tour[-1]][tour[0]]\n",
    "    return value\n",
    "\n",
    "def CheckDomination(solution_1, solution_2):\n",
    "    solution_1_cost = Evaluate(solution_1, cost_matrix)\n",
    "    solution_1_dist = Evaluate(solution_1, distance_matrix)\n",
    "    solution_2_cost = Evaluate(solution_2, cost_matrix)\n",
    "    solution_2_dist = Evaluate(solution_2, distance_matrix)\n",
    "\n",
    "    dist_comp_eql_p = solution_1_dist <= solution_2_dist\n",
    "    cost_comp_eql_p = solution_1_cost <= solution_2_cost\n",
    "    dist_comp_p = solution_1_dist < solution_2_dist\n",
    "    cost_comp_p = solution_1_cost < solution_2_cost\n",
    "\n",
    "    dist_comp_eql_q = solution_1_dist >= solution_2_dist\n",
    "    cost_comp_eql_q = solution_1_cost >= solution_2_cost\n",
    "    dist_comp_q = solution_1_dist > solution_2_dist\n",
    "    cost_comp_q = solution_1_cost > solution_2_cost\n",
    "\n",
    "    if ((dist_comp_eql_p and cost_comp_eql_p) and (dist_comp_p or cost_comp_p)):\n",
    "        return 1\n",
    "    elif ((dist_comp_eql_q and cost_comp_eql_q) and (dist_comp_q or cost_comp_q)):\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def FastNonDominatedSort(population):\n",
    "    population_data = {}\n",
    "    fronts = []\n",
    "    solution_p = 0\n",
    "    while solution_p < len(population):\n",
    "        sols_dom_by_p = []\n",
    "        dom_count_p = 0\n",
    "        solution_q = 0\n",
    "        while solution_q < len(population):\n",
    "            dom_p_q = CheckDomination(population[solution_p], population[solution_q])\n",
    "            # if p dominates q\n",
    "            if dom_p_q == 1:\n",
    "                sols_dom_by_p.append(solution_q)\n",
    "            # if q dominates p\n",
    "            elif dom_p_q == -1:\n",
    "                dom_count_p += 1\n",
    "            solution_q += 1\n",
    "        population_data[solution_p] = {\n",
    "            \"dominates\": sols_dom_by_p,\n",
    "            \"dominationCount\": dom_count_p,\n",
    "        }\n",
    "        solution_p += 1\n",
    "    while len(population_data):\n",
    "        new_front = []\n",
    "        for i in population_data:\n",
    "            if population_data[i][\"dominationCount\"] == 0:\n",
    "                new_front.append(i)\n",
    "        for j in new_front:\n",
    "            for submissive in population_data[j][\"dominates\"]:\n",
    "                population_data[submissive][\"dominationCount\"] -= 1\n",
    "            del population_data[j]\n",
    "        fronts.append(new_front)\n",
    "    return fronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbcbcd9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Evaluate(tour, matrix):\n",
    "    value = 0\n",
    "    i = 0\n",
    "    while i < (len(tour)-1):\n",
    "        value += matrix[tour[i]][tour[i+1]]\n",
    "        i += 1\n",
    "        pass\n",
    "    value += matrix[tour[-1]][tour[0]]\n",
    "    return value\n",
    "\n",
    "def CrowdingDistance(front, population):\n",
    "    distance = [0.0 for i in front]\n",
    "    fitness_cost_values = [] \n",
    "    fitness_dist_values = []\n",
    "    for i in front:\n",
    "        fitness_cost_values.append(Evaluate(population[i], cost_matrix))\n",
    "        fitness_dist_values.append(Evaluate(population[i], distance_matrix))\n",
    "    cost_indices = sorted(\n",
    "        range(len(fitness_cost_values)), \n",
    "        key=lambda k: fitness_cost_values[k],\n",
    "        reverse=True\n",
    "    )\n",
    "    dist_indices = sorted(\n",
    "        range(len(fitness_dist_values)), \n",
    "        key=lambda k: fitness_dist_values[k],\n",
    "        reverse=True\n",
    "    )\n",
    "    # Should we take maximum and minimum fitness value possible of the current front\n",
    "    # or the whole population?\n",
    "    diff_cost_max = max(fitness_cost_values) - min(fitness_cost_values)\n",
    "    diff_dist_max = max(fitness_dist_values) - min(fitness_dist_values)\n",
    "    distance[cost_indices[0]] = math.inf\n",
    "    distance[cost_indices[-1]] = math.inf\n",
    "    i = 1\n",
    "    while i < (len(front)-1):\n",
    "        distance[cost_indices[i]] += (fitness_cost_values[cost_indices[i-1]] - fitness_cost_values[cost_indices[i+1]]) / diff_cost_max \n",
    "        i += 1\n",
    "    distance[dist_indices[0]] = math.inf\n",
    "    distance[dist_indices[-1]] = math.inf\n",
    "    i = 1\n",
    "    while i < (len(front)-1):\n",
    "        distance[dist_indices[i]] += (fitness_dist_values[dist_indices[i-1]] - fitness_dist_values[dist_indices[i+1]]) / diff_dist_max \n",
    "        i += 1\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d771fbd6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Selection(population):\n",
    "    a, b = random.sample(range(len(population)), 2)\n",
    "    parentA = population[a]\n",
    "    parentB = population[b]\n",
    "    return parentA, parentB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563e4be5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Crossover(parent1, parent2):\n",
    "    if len(parent1) != len(parent2):\n",
    "        return False\n",
    "    else:\n",
    "        child1 = [None for i in parent1]\n",
    "        child2 = [None for i in parent2]\n",
    "\n",
    "        # Generate 2 Random Points\n",
    "        a, b = sorted(random.sample(range(len(parent1)+1), 2))\n",
    "\n",
    "        # Indices to be Swapped\n",
    "        unfilled_indinces = []\n",
    "        for i in range(a):\n",
    "            unfilled_indinces.append(i)\n",
    "            pass\n",
    "        for i in range(b, len(parent1)):\n",
    "            unfilled_indinces.append(i)\n",
    "            pass\n",
    "\n",
    "        # Copy the Contents as it is\n",
    "        for i in range(a, b):\n",
    "            child1[i] = parent1[i]\n",
    "            child2[i] = parent2[i]\n",
    "            pass\n",
    "\n",
    "        # Swap from Parent2 to Child1\n",
    "        ind = 0\n",
    "        for i in parent2:\n",
    "            if i not in child1:\n",
    "                child1[unfilled_indinces[ind]] = i\n",
    "                ind += 1\n",
    "            pass\n",
    "\n",
    "        # Swap from Parent1 to Child2\n",
    "        ind = 0\n",
    "        for i in parent1:\n",
    "            if i not in child2:\n",
    "                child2[unfilled_indinces[ind]] = i\n",
    "                ind += 1\n",
    "            pass\n",
    "        return (child1, child2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa92822d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Mutation(chromosome):\n",
    "    # Generate 2 Random Points\n",
    "    a, b = sorted(random.sample(range(len(chromosome)), 2))\n",
    "    chromosome[a], chromosome[b] = chromosome[b], chromosome[a]\n",
    "    return chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43300721",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GenerateOffspring(parents):\n",
    "    offspring = []\n",
    "    while (len(offspring) != len(parents)):\n",
    "        parentA, parentB = Selection(parents)\n",
    "        childA, childB = Crossover(parentA, parentB)\n",
    "        childA = Mutation(childA)\n",
    "        childB = Mutation(childB)\n",
    "        offspring.append(childA)\n",
    "        offspring.append(childB)\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19442c7b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def GeneratePopulation(size, num_cities):\n",
    "    permutations = []   \n",
    "    for i in range(size):\n",
    "        tour = [j for j in range(num_cities)]\n",
    "        random.shuffle(tour)    \n",
    "        permutations.append(tour)\n",
    "        pass\n",
    "    return permutations\n",
    "\n",
    "def Evaluate(tour, matrix):\n",
    "    value = 0\n",
    "    i = 0\n",
    "    while i < (len(tour)-1):\n",
    "        value += matrix[tour[i]][tour[i+1]]\n",
    "        i += 1\n",
    "        pass\n",
    "    value += matrix[tour[-1]][tour[0]]\n",
    "    return value\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    population_size = 20\n",
    "    num_cities = 200\n",
    "    num_generations = 500\n",
    "    num_generations2 = 1000\n",
    "    num_generations3 = 2000\n",
    "    num_generations4 = 4000\n",
    "    # Initial Population \n",
    "    parents = GeneratePopulation(population_size, num_cities)\n",
    "    # Generate Children by Selection, Crossover and Mutation\n",
    "    children = GenerateOffspring(parents)\n",
    "    population = parents[:]\n",
    "    # NewPopulation = Parents + Children\n",
    "    population.extend(children)\n",
    "    gen_num = 0\n",
    "    while gen_num < num_generations:\n",
    "        children = GenerateOffspring(parents)\n",
    "        population = parents[:]\n",
    "        # NewPopulation = Parents + Children\n",
    "        population.extend(children)\n",
    "        # print (gen_num, \":\", len(population))\n",
    "        # for i in population:\n",
    "        #     print (i)\n",
    "        fronts = FastNonDominatedSort(population)\n",
    "#         for i in fronts:\n",
    "#             print (i)\n",
    "#         print (\"--\")\n",
    "        new_parents = []\n",
    "        for front in fronts:\n",
    "            if (len(front) + len(new_parents)) <= population_size:\n",
    "                for i in front:\n",
    "                    # print (population[i])\n",
    "                    new_parents.append(population[i])\n",
    "            else:\n",
    "                distance = CrowdingDistance(front, population)\n",
    "                indices = sorted(\n",
    "                    range(len(distance)), \n",
    "                    key=lambda k: distance[k],\n",
    "                    reverse=True\n",
    "                )\n",
    "                i = 0\n",
    "                while len(new_parents) != population_size:\n",
    "                    new_parents.append(population[indices[i]])\n",
    "                    i += 1\n",
    "        parents = new_parents[:] \n",
    "        gen_num += 1\n",
    "        pass\n",
    "    function1 = []\n",
    "    function2 = []\n",
    "    # print (\"Sol\")\n",
    "    for i in parents:\n",
    "        # print (i)\n",
    "        function1.append(Evaluate(i, distance_matrix))\n",
    "        function2.append(Evaluate(i, cost_matrix))\n",
    "\n",
    "        \n",
    "    #_____________________________________________________________________#\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(function1, function2,color='blue' )   \n",
    "    plt.scatter(objs[:,0],objs[:,1],color='red' )\n",
    "#     plt.figure()\n",
    "#     plt.plot(objs[:,0],objs[:,1],\"ro\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b668698",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    population_size = 20\n",
    "    num_cities = 200\n",
    "    num_generations = 500\n",
    "    num_generations2 = 1000\n",
    "    num_generations3 = 2000\n",
    "    num_generations4 = 4000\n",
    "    # Initial Population \n",
    "#_____________________________________________(2)_1000 step_________________________________#\n",
    "    parents2 = GeneratePopulation(population_size, num_cities)\n",
    "    # Generate Children by Selection, Crossover and Mutation\n",
    "    children2 = GenerateOffspring(parents2)\n",
    "    population2 = parents2[:]\n",
    "    # NewPopulation = Parents + Children\n",
    "    population2.extend(children2)\n",
    "    gen_num2 = 0\n",
    "    while gen_num2 < num_generations2:\n",
    "        children2 = GenerateOffspring(parents2)\n",
    "        population2 = parents2[:]\n",
    "        # NewPopulation = Parents + Children\n",
    "        population2.extend(children2)\n",
    "        fronts2 = FastNonDominatedSort(population2)\n",
    "#         for i in fronts:\n",
    "#             print (i)\n",
    "#         print (\"--\")\n",
    "        new_parents2 = []\n",
    "        for front in fronts2:\n",
    "            if (len(front) + len(new_parents2)) <= population_size:\n",
    "                for i in front:\n",
    "                    # print (population[i])\n",
    "                    new_parents2.append(population[i])\n",
    "            else:\n",
    "                distance = CrowdingDistance(front, population2)\n",
    "                indices = sorted(\n",
    "                    range(len(distance)), \n",
    "                    key=lambda k: distance[k],\n",
    "                    reverse=True\n",
    "                )\n",
    "                i = 0\n",
    "                while len(new_parents2) != population_size:\n",
    "                    new_parents2.append(population2[indices[i]])\n",
    "                    i += 1 \n",
    "        parents2 = new_parents2[:] \n",
    "        gen_num2 += 1\n",
    "        pass\n",
    "    function3 = []\n",
    "    function4 = []\n",
    "    for i in parents2:\n",
    "        function3.append(Evaluate(i, distance_matrix))\n",
    "        function4.append(Evaluate(i, cost_matrix))\n",
    "        \n",
    "    #_____________________________________________________________________#\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(function3, function4,color='grey' )  \n",
    "    plt.scatter(objs[:,0],objs[:,1],color='red' )\n",
    "#     plt.figure()\n",
    "#     plt.plot(objs[:,0],objs[:,1],\"ro\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76bfc66",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    population_size = 20\n",
    "    num_cities = 200\n",
    "    num_generations = 500\n",
    "    num_generations2 = 1000\n",
    "    num_generations3 = 2000\n",
    "    num_generations4 = 4000\n",
    "    # Initial Population \n",
    "        \n",
    "#_____________________________________________(3)_ 2000 step_________________________________#\n",
    "    parents3 = GeneratePopulation(population_size, num_cities)\n",
    "    # Generate Children by Selection, Crossover and Mutation\n",
    "    children3 = GenerateOffspring(parents3)\n",
    "    population3 = parents3[:]\n",
    "    # NewPopulation = Parents + Children\n",
    "    population3.extend(children3)\n",
    "    gen_num3 = 0\n",
    "    while gen_num3 < num_generations3:\n",
    "        children3 = GenerateOffspring(parents3)\n",
    "        population3 = parents3[:]\n",
    "        # NewPopulation = Parents + Children\n",
    "        population3.extend(children3)\n",
    "        fronts3 = FastNonDominatedSort(population3)\n",
    "#         for i in fronts:\n",
    "#             print (i)\n",
    "#         print (\"--\")\n",
    "        new_parents3 = []\n",
    "        for front in fronts3:\n",
    "            if (len(front) + len(new_parents3)) <= population_size:\n",
    "                for i in front:\n",
    "                    # print (population[i])\n",
    "                    new_parents3.append(population[i])\n",
    "            else:\n",
    "                distance = CrowdingDistance(front, population3)\n",
    "                indices = sorted(\n",
    "                    range(len(distance)), \n",
    "                    key=lambda k: distance[k],\n",
    "                    reverse=True\n",
    "                )\n",
    "                i = 0\n",
    "                while len(new_parents3) != population_size:\n",
    "                    new_parents3.append(population3[indices[i]])\n",
    "                    i += 1 \n",
    "        parents3 = new_parents3[:] \n",
    "        gen_num3 += 1\n",
    "        pass\n",
    "    function5 = []\n",
    "    function6 = []\n",
    "    for i in parents3:\n",
    "        function5.append(Evaluate(i, distance_matrix))\n",
    "        function6.append(Evaluate(i, cost_matrix))\n",
    "        \n",
    "    #_____________________________________________________________________#\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(function5, function6,color='aqua' )    \n",
    "    plt.scatter(objs[:,0],objs[:,1],color='red' )\n",
    "#     plt.figure()\n",
    "#     plt.plot(objs[:,0],objs[:,1],\"ro\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174212b2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    population_size = 20\n",
    "    num_cities = 200\n",
    "    num_generations = 500\n",
    "    num_generations2 = 1000\n",
    "    num_generations3 = 2000\n",
    "    num_generations4 = 4000\n",
    "    # Initial Population \n",
    "    \n",
    "    #_____________________________________________(4)4000 step__________________________________#\n",
    "    parents4 = GeneratePopulation(population_size, num_cities)\n",
    "    # Generate Children by Selection, Crossover and Mutation\n",
    "    children4 = GenerateOffspring(parents4)\n",
    "    population4 = parents4[:]\n",
    "    # NewPopulation = Parents + Children\n",
    "    population4.extend(children4)\n",
    "    gen_num4 = 0\n",
    "    while gen_num4 < num_generations4:\n",
    "        children4 = GenerateOffspring(parents4)\n",
    "        population4 = parents4[:]\n",
    "        # NewPopulation = Parents + Children\n",
    "        population4.extend(children4)\n",
    "        fronts4 = FastNonDominatedSort(population4)\n",
    "#         for i in fronts:\n",
    "#             print (i)\n",
    "#         print (\"--\")\n",
    "        new_parents4 = []\n",
    "        for front in fronts4:\n",
    "            if (len(front) + len(new_parents4)) <= population_size:\n",
    "                for i in front:\n",
    "                    # print (population[i])\n",
    "                    new_parents4.append(population[i])\n",
    "            else:\n",
    "                distance = CrowdingDistance(front, population4)\n",
    "                indices = sorted(\n",
    "                    range(len(distance)), \n",
    "                    key=lambda k: distance[k],\n",
    "                    reverse=True\n",
    "                )\n",
    "                i = 0\n",
    "                while len(new_parents4) != population_size:\n",
    "                    new_parents4.append(population4[indices[i]])\n",
    "                    i += 1 \n",
    "        parents4 = new_parents4[:] \n",
    "        gen_num4 += 1\n",
    "        pass\n",
    "    function7 = []\n",
    "    function8 = []\n",
    "    for i in parents4:\n",
    "        function7.append(Evaluate(i, distance_matrix))\n",
    "        function8.append(Evaluate(i, cost_matrix))\n",
    "        \n",
    "    #_____________________________________________________________________#\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.scatter(function7, function8,color='yellow' )    \n",
    "    plt.scatter(objs[:,0],objs[:,1],color='red' )\n",
    "#     plt.figure()\n",
    "#     plt.plot(objs[:,0],objs[:,1],\"ro\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4968111,
     "sourceId": 8359764,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4968130,
     "sourceId": 8359787,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4968143,
     "sourceId": 8359801,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8.192805,
   "end_time": "2024-05-08T18:51:56.087474",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-08T18:51:47.894669",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
